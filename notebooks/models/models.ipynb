{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy   \n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassRecall\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = MulticlassAUROC(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500000000000002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.75, 0.05, 0.05, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(torch.tensor([[0.14,0.21,0.64],[0.14,0.21,0.64]]),torch.tensor([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassAUROC\n",
    "preds = torch.tensor([[0.14,0.21,0.64],[0.14,0.21,0.64]])\n",
    "target = torch.tensor([2,1])\n",
    "metric = MulticlassAUROC(num_classes=3, average=\"macro\", thresholds=None)\n",
    "metric(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.dataloader import ResnetDataset\n",
    "from utils.transformations import CustomTransformations\n",
    "from models.resnet50 import MyopiaClasificationModel\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torchmetrics.functional import accuracy, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2de2c04fed4bc2a7d52b20e707bf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "train_features = ResnetDataset(\"../train.csv\",\"../../test/\",transform=CustomTransformations(1024))\n",
    "train_loader = DataLoader(train_features,batch_size=1,num_workers=1,shuffle=True)\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=4,\n",
    "    callbacks=[TQDMProgressBar()],\n",
    "    log_every_n_steps=4\n",
    ")\n",
    "\n",
    "miopia_model = MyopiaClasificationModel(1024)\n",
    "\n",
    "# Train the model ⚡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | ResNet50TF         | 23.5 M\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "2 | auc      | MulticlassAUROC    | 0     \n",
      "------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.057    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67f3fa0886e4aedbee0195d5ba49210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('step', ...)` in your `training_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(miopia_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 4)\n",
    "a\n",
    "torch.argmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6685,  0.2749,  0.2660,  0.6036],\n",
       "        [-0.7418, -0.6860, -2.2189,  0.3964],\n",
       "        [ 0.5385,  1.5238,  2.0222,  1.3556]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.createCSV import createCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/models\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "createCSV(\"../../test/\",\"../\",\"../utils/customData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcreateCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /workspace/notebooks/utils/createCSV.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "createCSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path donde está el modelo resnet con los pesos\n",
    "!cp /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../test/P0212.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../test/N0002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../test/P0002.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../test/P0001.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                imgPath  label\n",
       "0  ../../test/P0212.jpg      2\n",
       "1  ../../test/N0002.jpg      1\n",
       "2  ../../test/P0002.jpg      2\n",
       "3  ../../test/P0001.jpg      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../test/P0001.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3,\"imgPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = read_image(\"../../test/H0001.jpg\").type_as(torch.FloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = transforms.Resize((512,512))(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x =torch.rand(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4291, 0.9208, 0.0894]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2988, 0.4885, 0.2127]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = torch.tensor([2])\n",
    "label = F.one_hot(label, 3).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1465)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(yhat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = torch.nn.Conv2d(3,3, (3,3), stride=1, padding=1)(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1024-3)/2 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(512-3 + 1 )/2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".fc = nn.Linear(512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2  # 1 class (person) + background\n",
    "\n",
    "print(model.fc)\n",
    "# 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048,3,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7326, 0.1827, 0.0847],\n",
       "        [0.1458, 0.1674, 0.6867]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 16:44:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 512.15       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8    N/A /  N/A |     92MiB /  4096MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        20      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        22      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        26      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from utils.createCSV import resnetCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnetCSV(\"../../data/Training/PALM-Training400\",\"../train_resnet50\",\"../utils/filteredH.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import math\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchmetrics import Accuracy   \n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassRecall\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4035b6c3eb4f4b8ce9b4e339a6f1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | ResNet50TF         | 23.5 M\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "2 | auc      | MulticlassAUROC    | 0     \n",
      "3 | recall   | MulticlassRecall   | 0     \n",
      "------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.057    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58008504303e4320aacbae5e5cca811d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('step', ...)` in your `training_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    import sys\n",
    "    sys.path.insert(0,\"../\")\n",
    "    from utils.dataloader import CustomImageDataset\n",
    "    from utils.transformations import CustomTransformations\n",
    "    from models.resnet50 import MyopiaClasificationModel\n",
    "    from pytorch_lightning import Trainer\n",
    "    from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "    from torchmetrics.functional import accuracy, auroc\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    config = {\n",
    "        \"batch_size\":1,\n",
    "        \"img_size\":1024,\n",
    "        \"num_workers\":2,\n",
    "        \"num_classes\":3,\n",
    "        \"lr\":1e-3\n",
    "    }\n",
    "    \n",
    "    \n",
    "    pl.seed_everything(42,workers=True)\n",
    "    train_features = CustomImageDataset(\"../train_resnet50/train_resnet50.csv\",\"../../train_resnet50/\",transform=CustomTransformations(config[\"img_size\"]))\n",
    "    train_loader = DataLoader(train_features,batch_size=config[\"batch_size\"],num_workers=config[\"num_workers\"],shuffle=True)\n",
    "\n",
    "    # Initialize a trainer\n",
    "    trainer = Trainer(\n",
    "        accumulate_grad_batches=32, # acumula los gradientes de los primeros 4 batches\n",
    "        #deterministic=True,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "        max_epochs=1000,\n",
    "        callbacks=[TQDMProgressBar(),\n",
    "                   EarlyStopping(monitor=\"train_val_loss\",mode=\"min\",patience=3),\n",
    "                   ModelCheckpoint(dirpath=\"./model-checkpoint/\",\\\n",
    "                    filename=\"{epoch}-{train_val_acc:.2f}\",\n",
    "                    save_top_k=2, \n",
    "                    monitor=\"train_val_loss\")],\n",
    "        log_every_n_steps=1,\n",
    "        # resume_from_checkpoint=\"some/path/to/my_checkpoint.ckpt\"\n",
    "    )\n",
    "    \n",
    "    val_loader = train_loader\n",
    "    #test_loader = train_loader\n",
    "\n",
    "    miopia_model = MyopiaClasificationModel(config)\n",
    "    trainer.fit(miopia_model, train_loader,val_loader)\n",
    "    #trainer.test(miopia_model,test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyopiaClasificationModel(\n",
       "  (model): ResNet50TF(\n",
       "    (resNet50): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       "    )\n",
       "    (baseInputLayers): Sequential(\n",
       "      (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (accuracy): MulticlassAccuracy()\n",
       "  (auc): MulticlassAUROC()\n",
       "  (recall): MulticlassRecall()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "from models.resnet50 import MyopiaClasificationModel\n",
    "from utils.dataloader import ResnetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "config = {\n",
    "        \"batch_size\":1,\n",
    "        \"img_size\":1024,\n",
    "        \"num_workers\":2,\n",
    "        \"num_classes\":3,\n",
    "        \"lr\":1e-3\n",
    "    }\n",
    "model = MyopiaClasificationModel.load_from_checkpoint(\"./model-checkpoint/resnet50-epoch=1-train_val_acc=0.71.ckpt\")\n",
    "\n",
    "val_dataset = ResnetDataset(\"../train_resnet50/val_resnet50.csv\",\"../../train_resnet50/\",transform=None)\n",
    "val_loader = DataLoader(val_dataset,batch_size=config[\"batch_size\"],num_workers=config[\"num_workers\"],shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "predicted = np.array([])\n",
    "target = np.array([])\n",
    "for x,y in val_loader:\n",
    "    yhat = model(x)\n",
    "    y_pred = torch.argmax(yhat, dim=1).cpu().numpy() # predicted labels\n",
    "    y_true = y.cpu().numpy() # true labels\n",
    "    predicted = np.append(predicted,y_pred)\n",
    "    target = np.append(target,y_true)\n",
    "    break\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286it [10:41,  2.24s/it]                       \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "from models.resnet50 import MyopiaClasificationModel\n",
    "from utils.dataloader import ResnetDataset\n",
    "from utils.transformations import CustomTransformations\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "config = {\n",
    "        \"batch_size\":2,\n",
    "        \"img_size\":1024,\n",
    "        \"num_workers\":2,\n",
    "        \"num_classes\":3,\n",
    "        \"lr\":1e-3\n",
    "    }\n",
    "model = MyopiaClasificationModel.load_from_checkpoint(\"./model-checkpoint/resnet50-epoch=1-train_val_acc=0.71.ckpt\")\n",
    "\n",
    "val_dataset = ResnetDataset(\"../train_resnet50/train_resnet50.csv\",\"../../train_resnet50/\",transform=CustomTransformations(config[\"img_size\"]))\n",
    "val_loader = DataLoader(val_dataset,batch_size=config[\"batch_size\"],num_workers=config[\"num_workers\"],shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "import numpy as np \n",
    "predicted = np.array([])\n",
    "target = np.array([])\n",
    "from tqdm import tqdm\n",
    "with tqdm(total=72) as pbar:\n",
    "    for x,y in val_loader:\n",
    "        with torch.no_grad():\n",
    "            yhat = model(x)\n",
    "        y_pred = torch.argmax(yhat, dim=1).cpu().numpy() # predicted labels\n",
    "        y_true = y.cpu().numpy() # true labels\n",
    "        predicted = np.append(predicted,y_pred)\n",
    "        target = np.append(target,y_true)\n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(target,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  1],\n",
       "       [ 0, 26,  8],\n",
       "       [ 0,  1, 33]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.6.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xticklabels=[\"H\",\"N\",\"M\"]\n",
    "sns.heatmap(conf,annot=True,cmap=\"coolwarm\",xticklabels=xticklabels,yticklabels=xticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xticklabels=[\"H\",\"N\",\"M\"]\n",
    "sns.heatmap(cm_norm,annot=True,cmap=\"coolwarm\",xticklabels=xticklabels,yticklabels=xticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_norm = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
